{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature_extraction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "v9QEtspKz8U9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display\n",
        "from seaborn import color_palette\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_BATCH_NORM_DECAY = 0.9\n",
        "_BATCH_NORM_EPSILON = 1e-05\n",
        "_LEAKY_RELU = 0.1"
      ],
      "metadata": {
        "id": "USUTGuLY2YLI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_norm(inputs, training, data_format):\n",
        "    return tf.layers.batch_normalization(inputs=inputs, axis=1 if data_format == 'channels_first' else 3,\n",
        "           momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON,scale=True, training=training)\n",
        "    \n",
        "def fixed_padding(inputs, kernel_size, data_format):\n",
        "    pad_total = kernel_size - 1\n",
        "    pad_beg = pad_total // 2\n",
        "    pad_end = pad_total - pad_beg\n",
        "    if data_format == 'channels_first':\n",
        "        padded_inputs = tf.pad(inputs, [[0, 0], [0, 0],[pad_beg, pad_end],[pad_beg, pad_end]])\n",
        "    else:\n",
        "        padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg, pad_end],[pad_beg, pad_end], [0, 0]])\n",
        "    return padded_inputs\n",
        "    \n",
        "def conv2d_fixed_padding(inputs, filters, kernel_size, data_format, strides=1):\n",
        "    if strides > 1:\n",
        "     inputs = fixed_padding(inputs, kernel_size, data_format)\n",
        "    return tf.layers.conv2d(inputs=inputs, filters=filters, kernel_size=kernel_size,strides=strides, \n",
        "           padding=('SAME' if strides == 1 else 'VALID'),use_bias=False, data_format=data_format)"
      ],
      "metadata": {
        "id": "OeJMrHyR2NlP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def darknet53_residual_block(inputs, filters, training, data_format,\n",
        "                             strides=1):\n",
        "    \"\"\"Creates a residual block for Darknet.\"\"\"\n",
        "    shortcut = inputs\n",
        "\n",
        "    inputs = conv2d_fixed_padding(\n",
        "        inputs, filters=filters, kernel_size=1, strides=strides,\n",
        "        data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(\n",
        "        inputs, filters=2 * filters, kernel_size=3, strides=strides,\n",
        "        data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs += shortcut\n",
        "\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "Mb8LiCv21XGx"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def darknet53(inputs, training, data_format):\n",
        "    \"\"\"Creates Darknet53 model for feature extraction.\"\"\"\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=32, kernel_size=3,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=64, kernel_size=3,\n",
        "                                  strides=2, data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = darknet53_residual_block(inputs, filters=32, training=training,\n",
        "                                      data_format=data_format)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=128, kernel_size=3,\n",
        "                                  strides=2, data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    for _ in range(2):\n",
        "        inputs = darknet53_residual_block(inputs, filters=64,\n",
        "                                          training=training,\n",
        "                                          data_format=data_format)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=256, kernel_size=3,\n",
        "                                  strides=2, data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    for _ in range(8):\n",
        "        inputs = darknet53_residual_block(inputs, filters=128,\n",
        "                                          training=training,\n",
        "                                          data_format=data_format)\n",
        "\n",
        "    route1 = inputs\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=512, kernel_size=3,\n",
        "                                  strides=2, data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    for _ in range(8):\n",
        "        inputs = darknet53_residual_block(inputs, filters=256,\n",
        "                                          training=training,\n",
        "                                          data_format=data_format)\n",
        "\n",
        "    route2 = inputs\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=1024, kernel_size=3,\n",
        "                                  strides=2, data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    for _ in range(4):\n",
        "        inputs = darknet53_residual_block(inputs, filters=512,\n",
        "                                          training=training,\n",
        "                                          data_format=data_format)\n",
        "\n",
        "    return route1, route2, inputs"
      ],
      "metadata": {
        "id": "qv3Zx5zi1aXx"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}